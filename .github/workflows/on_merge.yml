name: Production Image Processing (Merge)

on:
  push:
    branches:
      - main
    paths:
      - 'images/**'

env:
  AWS_REGION: us-east-1
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_ROLE_ARN: ${{ secrets.AWS_ROLE_ARN }}
  S3_BUCKET: ${{ secrets.S3_BUCKET }}
  DYNAMODB_TABLE_PROD: ${{ secrets.DYNAMODB_TABLE_PROD }}

jobs:
  upload-to-prod:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Find changed images
        id: changed-files
        uses: tj-actions/changed-files@v41
        with:
          files: |
            images/**/*.jpg
            images/**/*.jpeg
            images/**/*.png
            images/**/*

      - name: Upload images to S3 Production
        if: steps.changed-files.outputs.any_changed == 'true'
        run: |
          echo "Uploading images to Production environment (rekognition-input/prod/)"
          for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
            filename=$(basename "$file")
            echo "Uploading: $filename"
            aws s3 cp "$file" "s3://${S3_BUCKET}/rekognition-input/prod/${filename}" \
              --metadata "environment=prod,branch=main,commit-sha=${GITHUB_SHA}"
            echo "Uploaded to s3://${S3_BUCKET}/rekognition-input/prod/${filename}"
          done

      - name: Validate DynamoDB Results
        if: steps.changed-files.outputs.any_changed == 'true'
        run: |
          set -e  # Exit on error

          echo "Validating results in DynamoDB table: ${DYNAMODB_TABLE_PROD}"
          echo "Region: ${AWS_REGION}"

          check_dynamodb_query() {
            local s3_key="$1"
            local max_attempts=6
            local wait_time=5

            filename=$(basename "$s3_key")

            for attempt in $(seq 1 $max_attempts); do
              echo "  Attempt $attempt/$max_attempts..."

              set +e
              result=$(aws dynamodb query \
                --table-name "${DYNAMODB_TABLE_PROD}" \
                --region "${AWS_REGION}" \
                --key-condition-expression "filename = :f" \
                --expression-attribute-values "{\":f\":{\"S\":\"${filename}\"}}" \
                --select COUNT 2>&1)
              query_exit_code=$?
              set -e

              if [ $query_exit_code -ne 0 ]; then
                echo "  AWS CLI error:"
                echo "$result" | head -n 5

                if echo "$result" | grep -q "AccessDenied\|UnauthorizedOperation"; then
                  echo ""
                  echo "  Permission error! GitHub Actions role needs dynamodb:Query permission"
                  return 1
                elif echo "$result" | grep -q "ResourceNotFoundException"; then
                  echo ""
                  echo "  Table not found! Verify table name: ${DYNAMODB_TABLE_PROD}"
                  return 1
                fi

                if [ $attempt -lt $max_attempts ]; then
                  echo "  Retrying after ${wait_time} seconds..."
                  sleep $wait_time
                  continue
                else
                  return 1
                fi
              fi

              count=$(echo "$result" | jq -r '.Count // "0"' 2>/dev/null || echo "0")

              if [ "$count" -gt 0 ]; then
                echo "  Results found in DynamoDB (filename=${filename}, items=${count})"
                return 0
              else
                if [ $attempt -lt $max_attempts ]; then
                  echo "  No results yet, waiting ${wait_time} seconds..."
                  sleep $wait_time
                else
                  echo "  No results found after $max_attempts attempts"
                  return 1
                fi
              fi
            done
          }

          success_count=0
          fail_count=0

          for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
            filename=$(basename "$file")
            s3_key="rekognition-input/prod/${filename}"

            echo ""
            echo "========================================="
            echo "Checking for results via Query: ${s3_key}"
            echo "========================================="

            if check_dynamodb_query "$s3_key"; then
              success_count=$((success_count + 1))
            else
              fail_count=$((fail_count + 1))
              echo ""
              echo "  Troubleshooting hints:"
              echo "  1. Check Lambda logs:"
              echo "     aws logs tail /aws/lambda/rekognition-prod-handler --follow --region ${AWS_REGION}"
              echo "  2. Verify S3 file was uploaded:"
              echo "     aws s3 ls s3://${S3_BUCKET}/${s3_key}"
              echo "  3. Check table contents:"
              echo "     aws dynamodb scan --table-name ${DYNAMODB_TABLE_PROD} --region ${AWS_REGION}"
            fi
          done

          echo ""
          echo "========================================="
          echo "Production validation complete!"
          echo "========================================="
          echo "  Successful: ${success_count}"
          echo "  Failed: ${fail_count}"
          echo ""

          if [ $fail_count -gt 0 ]; then
            echo "Some images were not processed successfully"
            echo ""
            echo "Common causes:"
            echo "  1. Lambda function hasn’t finished processing (usually takes 5-10 seconds)"
            echo "  2. Lambda function encountered an error (check CloudWatch logs)"
            echo "  3. S3 event notification not configured correctly"
            echo "  4. Lambda doesn’t have permission to write to DynamoDB"
            echo ""
            exit 1
          fi

          echo "All images validated successfully!"

      - name: Create deployment summary
        if: steps.changed-files.outputs.any_changed == 'true'
        run: |
          echo "## Production Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** Production" >> $GITHUB_STEP_SUMMARY
          echo "**S3 Location:** \`rekognition-input/prod/\`" >> $GITHUB_STEP_SUMMARY
          echo "**DynamoDB Table:** \`${DYNAMODB_TABLE_PROD}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Images Processed" >> $GITHUB_STEP_SUMMARY

          for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
            filename=$(basename "$file")
            echo "- \`${filename}\`" >> $GITHUB_STEP_SUMMARY
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All images uploaded and analyzed successfully via Lambda function." >> $GITHUB_STEP_SUMMARY