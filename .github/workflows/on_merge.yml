name: Production Image Processing (Merge)

on:
  push:
    branches:
      - main
    paths:
      - 'images/**'

env:
  AWS_REGION: us-east-1
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  S3_BUCKET: ${{ secrets.S3_BUCKET }}
  DYNAMODB_TABLE: prod_results

jobs:
  upload-to-prod:
    runs-on: ubuntu-latest
    
    permissions:
      id-token: write
      contents: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Find changed images
        id: changed-files
        uses: tj-actions/changed-files@v41
        with:
          files: |
            images/**/*.jpg
            images/**/*.jpeg
            images/**/*.png
      
      - name: Upload images to S3 Production
        if: steps.changed-files.outputs.any_changed == 'true'
        run: |
          echo "Uploading images to Production environment (rekognition-input/prod/)"
          for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
            filename=$(basename "$file")
            echo "Uploading: $filename"
            aws s3 cp "$file" "s3://${S3_BUCKET}/rekognition-input/prod/${filename}" \
              --metadata "environment=prod,branch=main,commit-sha=${GITHUB_SHA}"
            echo "âœ“ Uploaded to s3://${S3_BUCKET}/rekognition-input/prod/${filename}"
          done
      
      - name: Validate DynamoDB Results
        if: steps.changed-files.outputs.any_changed == 'true'
        run: |
          echo "Validating results in DynamoDB table: ${DYNAMODB_TABLE}"
          
          # Function to check DynamoDB for results with retries
          check_dynamodb() {
            local s3_key=$1
            local max_attempts=6
            local wait_time=5
            
            for attempt in $(seq 1 $max_attempts); do
              echo "  Attempt $attempt/$max_attempts..."
              
              # Query DynamoDB for the item
              result=$(aws dynamodb get-item \
                --table-name "${DYNAMODB_TABLE}" \
                --key "{\"filename\": {\"S\": \"${s3_key}\"}}" \
                --region "${AWS_REGION}" \
                2>&1 || echo "ERROR")
              
              # Check if item exists
              if echo "$result" | grep -q '"Item"'; then
                echo "  âœ“ Results found in DynamoDB"
                
                # Extract and display label count
                label_count=$(echo "$result" | jq -r '.Item.label_count.N // "0"')
                echo "    Label count: ${label_count}"
                
                # Display labels
                echo "    Labels detected:"
                echo "$result" | jq -r '.Item.labels.L[]? | "      - \(.M.Name.S): \(.M.Confidence.N)%"' 2>/dev/null || echo "      (unable to parse labels)"
                
                return 0
              else
                if [ $attempt -lt $max_attempts ]; then
                  echo "  â³ Results not found yet, waiting ${wait_time} seconds..."
                  sleep $wait_time
                else
                  echo "  âŒ Results not found after $max_attempts attempts"
                  return 1
                fi
              fi
            done
          }
          
          # Process each changed file
          success_count=0
          fail_count=0
          
          for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
            filename=$(basename "$file")
            s3_key="rekognition-input/prod/${filename}"
            
            echo ""
            echo "Checking for results: ${s3_key}"
            
            if check_dynamodb "$s3_key"; then
              ((success_count++))
            else
              ((fail_count++))
              echo "  âš  Warning: Lambda may not have processed this image yet"
              echo "  Check Lambda logs: aws logs tail /aws/lambda/rekognition-prod-handler --follow"
            fi
          done
          
          echo ""
          echo "========================================="
          echo "Production validation complete!"
          echo "  Successful: ${success_count}"
          echo "  Failed: ${fail_count}"
          echo "========================================="
          
          # Exit with error if any validations failed
          if [ $fail_count -gt 0 ]; then
            echo ""
            echo "âŒ Some images were not processed successfully"
            echo "This could mean:"
            echo "  1. Lambda function hasn't finished processing yet (wait longer)"
            echo "  2. Lambda function encountered an error (check CloudWatch logs)"
            echo "  3. S3 event notification not configured correctly"
            exit 1
          fi
      
      - name: Create deployment summary
        if: steps.changed-files.outputs.any_changed == 'true'
        run: |
          echo "## ðŸš€ Production Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** Production" >> $GITHUB_STEP_SUMMARY
          echo "**S3 Location:** \`rekognition-input/prod/\`" >> $GITHUB_STEP_SUMMARY
          echo "**DynamoDB Table:** \`${DYNAMODB_TABLE}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Images Processed" >> $GITHUB_STEP_SUMMARY
          
          for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
            filename=$(basename "$file")
            echo "- âœ… \`${filename}\`" >> $GITHUB_STEP_SUMMARY
          done
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All images uploaded and analyzed successfully via Lambda function." >> $GITHUB_STEP_SUMMARY